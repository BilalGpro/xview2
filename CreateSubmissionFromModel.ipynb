{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Submission From Model\n",
    "\n",
    "Run inference on the test images to create results ready for submission. This will create a folder called `submission` in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9_FzH13EjseR",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.evaluation.xview_evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZyAvNCJMmvFF",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# You may need to restart your runtime prior to this, to let your installation take effect\n",
    "# Some basic setup\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import shutil\n",
    "import cv2\n",
    "import random\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some parameters.\n",
    "LOCALIZATION_SUBMISSION_FOLDER = \"SUBMISSION_LOCALIZATION\"\n",
    "LOCALIZATION_MODEL_CONFIG = \"./detectron2_repo/configs/xview/mask_rcnn_R_50_FPN_3x.yaml\"\n",
    "DAMAGE_SUBMISSION_FOLDER = \"SUBMISSION_DAMAGE\"\n",
    "# DAMAGE_MODEL_CONFIG = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes and creates folders (clears them).\n",
    "shutil.rmtree(LOCALIZATION_SUBMISSION_FOLDER, ignore_errors=True)\n",
    "shutil.rmtree(DAMAGE_SUBMISSION_FOLDER, ignore_errors=True)\n",
    "os.mkdir(LOCALIZATION_SUBMISSION_FOLDER)\n",
    "os.mkdir(DAMAGE_SUBMISSION_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7unkuuiqLdqd",
    "outputId": "aba59cf2-f198-4269-eaca-ae7e1f1fb6dc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "# Load localization model.\n",
    "cfg_localization = get_cfg()\n",
    "cfg_localization.merge_from_file(LOCALIZATION_MODEL_CONFIG)\n",
    "# Load localization checkpoint.\n",
    "cfg_localization.MODEL.WEIGHTS = os.path.join(cfg_localization.OUTPUT_DIR, \"model_0054999.pth\")\n",
    "cfg_localization.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7 # set the testing threshold for this model\n",
    "predictor_localization = DefaultPredictor(cfg_localization)\n",
    "\n",
    "# Load damage model.\n",
    "# cfg_damage = get_cfg()\n",
    "# cfg_damage.merge_from_file(DAMAGE_MODEL_CONFIG)\n",
    "# Load damage checkpoint.\n",
    "# cfg_damage.MODEL.WEIGHTS = os.path.join(cfg_damage.OUTPUT_DIR, \"model_0054999.pth\")\n",
    "# cfg_damage.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7 # set the testing threshold for this model\n",
    "# predictor_damage = DefaultPredictor(cfg_damage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_filenames = sorted(glob.glob(\"data/test/images/*\"))\n",
    "for filename in image_filenames:\n",
    "    # Load the image.\n",
    "    image = cv2.imread(filename)\n",
    "    \n",
    "    # Choose the model type based on pre or post localization\n",
    "    if filename.find(\"pre\") >= 0:\n",
    "        # LOCALIZATION model.\n",
    "        outputs = predictor_localization(image)\n",
    "    \n",
    "        # get to the right format\n",
    "        instances = outputs[\"instances\"].to('cpu')\n",
    "        # use RLE to encode the masks, because they are too large and takes memory\n",
    "        # since this evaluator stores outputs of the entire dataset\n",
    "        # Our model may predict bool array, but cocoapi expects uint8\n",
    "        rles = [\n",
    "            mask_util.encode(np.array(mask[:, :, None], order=\"F\", dtype=\"uint8\"))[0]\n",
    "            for mask in instances.pred_masks\n",
    "        ]\n",
    "        for rle in rles:\n",
    "            # \"counts\" is an array encoded by mask_util as a byte-stream. Python3's\n",
    "            # json writer which always produces strings cannot serialize a bytestream\n",
    "            # unless you decode it. Thankfully, utf-8 works out (which is also what\n",
    "            # the pycocotools/_mask.pyx does).\n",
    "            rle[\"counts\"] = rle[\"counts\"].decode(\"utf-8\")\n",
    "        instances.pred_masks_rle = rles\n",
    "        instances.remove(\"pred_masks\")\n",
    "        prediction = {}\n",
    "        prediction[\"instances\"] = instances_to_json(instances)\n",
    "        height = 1024\n",
    "        width = 1024\n",
    "        \n",
    "        pred_image = get_xview_localization_pred_image(height, width, prediction)\n",
    "        \n",
    "        name = os.path.basename(filename)\n",
    "        new_filename = name.replace(\"pre\", \"localization\")[:-4] + \"_prediction.png\"\n",
    "        submission_filename = os.path.join(LOCALIZATION_SUBMISSION_FOLDER, new_filename)\n",
    "        \n",
    "        print(submission_filename)\n",
    "        cv2.imwrite(submission_filename, pred_image)\n",
    "        \n",
    "    elif filename.find(\"post\") >= 0:\n",
    "        # DAMAGE model.\n",
    "        # TODO: pretty much a repeat of localization but for damage\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = cv2.imread(\"data/test/images/test_pre_00000.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pred_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
